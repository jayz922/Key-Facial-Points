{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBIKezc7_xOp"
   },
   "source": [
    "# Initial Imports / Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "XdtYpfwsw2xy",
    "outputId": "7684a696-d7ad-4bcf-e28f-03c36d6b3e45",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKIXGK4Ew2yG"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "facialpoints_df = pd.read_csv('KeyFacialPoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0AtcAmxGw2yN",
    "outputId": "feb49cdd-d75e-4cc6-ba2f-07ce57734eb8"
   },
   "outputs": [],
   "source": [
    "facialpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facialpoints_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "facialpoints_df['Image'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdOlt8Qkw2yR"
   },
   "outputs": [],
   "source": [
    "# format string from 1d to 2d string\n",
    "facialpoints_df['Image'] = facialpoints_df['Image'].apply(lambda x: np.fromstring(x, dtype= int, sep = ' ').reshape(96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of resized image\n",
    "facialpoints_df['Image'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "WCqOFMHAw2yi",
    "outputId": "a700d3e9-f405-43bd-bcd1-84b0a53ea983"
   },
   "outputs": [],
   "source": [
    "# confirm no null values\n",
    "facialpoints_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "036r_4I9BmsS"
   },
   "source": [
    "# Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "gJCIaUG1BIlI",
    "outputId": "aec8b0ad-21f5-4f22-fb71-28a7fd7f837f"
   },
   "outputs": [],
   "source": [
    "# Plot a random image from the dataset along with facial keypoints. \n",
    "i = np.random.randint(1, len(facialpoints_df))\n",
    "plt.imshow(facialpoints_df['Image'][i],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The (x, y) coordinates for the 15 key features are plotted on top of the image\n",
    "# Below is a for loop starting from index = 1 to 32 with step of 2\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(facialpoints_df['Image'][i],cmap='gray')\n",
    "for j in range(1,31,2):\n",
    "        plt.plot(facialpoints_df.loc[i][j-1], facialpoints_df.loc[i][j], 'rx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7FVhYoclw2ye",
    "outputId": "7bf1a32f-e643-43d5-dfd7-9b1df85693a7"
   },
   "outputs": [],
   "source": [
    "# images in a grid format\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)    \n",
    "    image = plt.imshow(facialpoints_df['Image'][i], cmap = 'gray')\n",
    "    for j in range(1,31,2):\n",
    "        plt.plot(facialpoints_df.loc[i][j-1], facialpoints_df.loc[i][j], 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4_G8_K6LZCv"
   },
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07kptUMkIrKy"
   },
   "outputs": [],
   "source": [
    "# Create a new copy of the dataframe\n",
    "import copy\n",
    "facialpoints_df_copy = copy.copy(facialpoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "z4JwoGNCIyfm",
    "outputId": "fbc038d4-9701-483f-f889-11ccdb67e249"
   },
   "outputs": [],
   "source": [
    "# obtain the header of the DataFrame (names of columns) \n",
    "\n",
    "columns = facialpoints_df_copy.columns[:-1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the pixel values of a sample image and see if it makes sense!\n",
    "facialpoints_df['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample image\n",
    "plt.imshow(facialpoints_df['Image'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipping image horizontally\n",
    "facialpoints_df_copy['Image'] = facialpoints_df_copy['Image'].apply(lambda x: np.flip(x, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test flipped image\n",
    "facialpoints_df_copy['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the image is flipped now\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOu2t2u5NRJ9"
   },
   "outputs": [],
   "source": [
    "# subtract our initial x-coordinate values from width of the image(96)\n",
    "for i in range(len(columns)):\n",
    "  if i%2 == 0:\n",
    "    facialpoints_df_copy[columns[i]] = facialpoints_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "C7iylFfhM_P_",
    "outputId": "0137caf4-3465-4354-ffc5-1c79af6765ce"
   },
   "outputs": [],
   "source": [
    "# View the Original image\n",
    "plt.imshow(facialpoints_df['Image'][0],cmap='gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df.loc[0][j-1], facialpoints_df.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "KvaGZ-lpM_c5",
    "outputId": "25cd4420-ac1a-4a18-8d07-61fbae21ef41"
   },
   "outputs": [],
   "source": [
    "# View the Horizontally flipped image\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap='gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df_copy.loc[0][j-1], facialpoints_df_copy.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubapElKTTt8n"
   },
   "outputs": [],
   "source": [
    "# Concatenate the original dataframe with the augmented dataframe\n",
    "facialpoints_df_augmented = np.concatenate((facialpoints_df,facialpoints_df_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Nggn0zuxUpTp",
    "outputId": "534bc443-1212-44d1-ad3f-0b31ed077e10"
   },
   "outputs": [],
   "source": [
    "# multiply pixel values by random values between 1 and 2 to increase the brightness of the image\n",
    "# we clip the value between 0 and 255\n",
    "\n",
    "import random\n",
    "\n",
    "facialpoints_df_copy = copy.copy(facialpoints_df)\n",
    "facialpoints_df_copy['Image'] = facialpoints_df['Image'].apply(lambda x:np.clip(random.uniform(1, 2) * x, 0.0, 255.0))\n",
    "facialpoints_df_augmented = np.concatenate((facialpoints_df_augmented, facialpoints_df_copy))\n",
    "facialpoints_df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "IGNQj6OTNiKQ",
    "outputId": "79341066-7849-49ec-d94f-c51bf5ac95d0"
   },
   "outputs": [],
   "source": [
    "# image with increased brightness\n",
    "\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap = 'gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df_copy.loc[0][j-1], facialpoints_df_copy.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jPV2vN36O8Dv",
    "outputId": "50d234d3-6a96-42f7-f2e5-9c57dd0ab30a"
   },
   "outputs": [],
   "source": [
    "# Randomly decrease image brightness\n",
    "# Multiply pixel values by random values between 0 and 1 to decrease the brightness of the image\n",
    "# Clip the value between 0 and 255\n",
    "\n",
    "facialpoints_df_copy = copy.copy(facialpoints_df)\n",
    "facialpoints_df_copy['Image'] = facialpoints_df['Image'].apply(lambda x:np.clip(random.uniform(0, 0.2) * x, 0.0, 255.0))\n",
    "facialpoints_df_augmented = np.concatenate((facialpoints_df_augmented, facialpoints_df_copy))\n",
    "facialpoints_df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df_copy['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "ZICLf2PHNqON",
    "outputId": "360c5b17-0911-455d-c667-5f0d81fbb0c9"
   },
   "outputs": [],
   "source": [
    "# sample image with decreased brightness decreased image\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap = 'gray')\n",
    "for j in range(1,31,2):\n",
    "        plt.plot(facialpoints_df_copy.loc[0][j-1], facialpoints_df_copy.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df_copy = copy.copy(facialpoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the image column vertically (note that axis = 0) \n",
    "facialpoints_df_copy['Image'] = facialpoints_df_copy['Image'].apply(lambda x: np.flip(x, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facialpoints_df_copy['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x coordinate stays the same for vertical flipping\n",
    "\n",
    "for i in range(len(columns)):\n",
    "  if i%2 == 1:\n",
    "    facialpoints_df_copy[columns[i]] = facialpoints_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Horizontally flipped image\n",
    "plt.imshow(facialpoints_df_copy['Image'][0], cmap='gray')\n",
    "for j in range(1, 31, 2):\n",
    "        plt.plot(facialpoints_df_copy.loc[0][j-1], facialpoints_df_copy.loc[0][j], 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUGZW71JOAMS"
   },
   "source": [
    "# Data normalization and prep for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Q69GW8LqI1c9",
    "outputId": "b6f7f799-a101-4e9e-b6e0-70784e66889c"
   },
   "outputs": [],
   "source": [
    "# Obtain the value of 'Images' and normalize it\n",
    "img = facialpoints_df_augmented[:, 30]\n",
    "img = img/255.\n",
    "\n",
    "# Create an empty array of shape (10700, 96, 96, 1) to train the model\n",
    "X = np.empty((len(img), 96, 96, 1))\n",
    "\n",
    "# Iterate through the normalized images list and add image values to the empty array \n",
    "for i in range(len(img)):\n",
    "  X[i,] = np.expand_dims(img[i], axis = 2)\n",
    "\n",
    "# Convert the array type to float32\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "JYFNwb6aIbcG",
    "outputId": "727caab4-fb2f-49b2-8632-1e2c4d76f9cc"
   },
   "outputs": [],
   "source": [
    "# Obtain the values of key face points coordinates, which are to used as target.\n",
    "y = facialpoints_df_augmented[:,:30]\n",
    "y = np.asarray(y).astype(np.float32)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "430yhQLKw2y6"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view more images in a grid format\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1)    \n",
    "    image = plt.imshow(X_train[i].reshape(96,96), cmap = 'gray')\n",
    "    for j in range(1,31,2):\n",
    "        plt.plot(y_train[i][j-1], y_train[i][j], 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mf-1c26gotLc"
   },
   "outputs": [],
   "source": [
    "def res_block(X, filter, stage):\n",
    "    \n",
    "  # CONVOLUTIONAL BLOCK\n",
    "  X_copy = X\n",
    "  f1 , f2, f3 = filter\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1), strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = MaxPool2D((2,2))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
    "\n",
    "  # Short path\n",
    "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
    "  X_copy = MaxPool2D((2,2))(X_copy)\n",
    "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
    "\n",
    "  # Add data from main and short paths\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    \n",
    "  # IDENTITY BLOCK 1\n",
    "  X_copy = X\n",
    "    \n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
    "\n",
    "  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    \n",
    "  # IDENTITY BLOCK 2\n",
    "  X_copy = X\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
    "\n",
    "  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1vs7m8W91JYS",
    "outputId": "f7d7a4a6-c4d5-4810-e6cb-dd75e683f289"
   },
   "outputs": [],
   "source": [
    "input_shape = (96,96,1)\n",
    "\n",
    "# Input tensor shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# Zero-padding\n",
    "X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "# Stage #1\n",
    "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
    "\n",
    "# Stage #2\n",
    "X = res_block(X, filter= [64,64,256], stage= 2)\n",
    "\n",
    "# Stage #3\n",
    "X = res_block(X, filter= [128,128,512], stage= 3)\n",
    "\n",
    "# Average Pooling\n",
    "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
    "\n",
    "# Final layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(4096, activation = 'relu')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(2048, activation = 'relu')(X)\n",
    "X = Dropout(0.1)(X)\n",
    "X = Dense(30, activation = 'relu')(X)\n",
    "\n",
    "\n",
    "model = Model( inputs= X_input, outputs = X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAAj64V1RaXk"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dfl9pCQQQlPe"
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v35ckVHHPgcb",
    "outputId": "812428bd-ead4-451b-e013-a9925965a658"
   },
   "outputs": [],
   "source": [
    "# save the best model with least validation loss\n",
    "#checkpointer = ModelCheckpoint(filepath = \"weights.hdf5\", verbose = 1, save_best_only = True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = \"weights.hdf5\", verbose = 1, save_best_only = True)\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs= 100, validation_split = 0.00015, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wz6VHutDRoni"
   },
   "source": [
    "# Assess performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Mv0VrvySPpzl",
    "outputId": "606482ad-c630-4c2b-eac6-e7e5a310259c"
   },
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "\n",
    "result = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy : {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "eS8ebDzOVo5t",
    "outputId": "42b92e94-8ff5-4887-fcfb-e58db7055442"
   },
   "outputs": [],
   "source": [
    "# Getting the model history keys \n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "hhKTH-4uVqTr",
    "outputId": "f4239f0e-bb5d-4f9c-c530-5ae95e3b0264"
   },
   "outputs": [],
   "source": [
    "# plot the training artifacts\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGA0O-yEl0Gt"
   },
   "outputs": [],
   "source": [
    "# Make prediction using the testing dataset\n",
    "df_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tvvsEkdKWNWV",
    "outputId": "feaa4315-70d5-43ae-dd67-f3db00459bb9"
   },
   "outputs": [],
   "source": [
    "# Print the rmse loss values\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, df_predict))\n",
    "print(\"RMSE value : {}\".format(rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "BT0h-JadTbeJ",
    "outputId": "191c5eb4-c945-4d03-fae9-33b6fea46cd3"
   },
   "outputs": [],
   "source": [
    "# Convert the predicted values into a dataframe\n",
    "\n",
    "df_predict= pd.DataFrame(df_predict, columns = columns)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "afMa9D2rTJye",
    "outputId": "959c7df9-0754-4d75-9e97-2641d77cebf4"
   },
   "outputs": [],
   "source": [
    "# Plot the test images and their predicted keypoints using the trained model\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(4, 2, i + 1)\n",
    "    # Using squeeze to convert the image shape from (96,96,1) to (96,96)\n",
    "    plt.imshow(X_test[i].squeeze(),cmap='gray')\n",
    "    for j in range(1,31,2):\n",
    "            plt.plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "facial_detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
